{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data.binary import BinaryCauseData\n",
    "from data.continuous import GaussianData\n",
    "\n",
    "from algorithm.base_test import TwoSampleConfounderTest, FullTwoSampleConfounderTest\n",
    "from algorithm.environment import EnvironmentTest\n",
    "\n",
    "from experiment import fast_experiment, save_results\n",
    "from plot_tools import set_mpl_default_settings, marker_dict\n",
    "\n",
    "set_mpl_default_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Comparing our procedure to the $Y \\perp E \\mid T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False\n",
    "\n",
    "# Data\n",
    "SimulateClass = BinaryCauseData \n",
    "\n",
    "# Experiment parameters\n",
    "nbr_env = [500]\n",
    "nbr_samples = [100]\n",
    "repetitions = 50\n",
    "sign_level = 0.05\n",
    "\n",
    "# Dataset\n",
    "conf_strength = [0,1]\n",
    "\n",
    "dist_param_list = []\n",
    "for y_b in list(np.linspace(0,.25,20)):\n",
    "          dist_param_list.append({ 'X': {'a': 0.0, 'b': 10},\n",
    "                                   'Y': {'a': 0.0, 'b': y_b},\n",
    "                                   'T': {'a': 0.0, 'b': 1}\n",
    "                                        })\n",
    "\n",
    "# Get timestamp for experiment\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%m%d%H%M\")\n",
    "print('Timestamp:', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load:\n",
    "# Run experiment with EnvironmentTest\n",
    "    env_test_res  =fast_experiment(dist_param_list,\n",
    "                                            nbr_env,\n",
    "                                            nbr_samples,\n",
    "                                            conf_strength,\n",
    "                                            SimulateClass, \n",
    "                                            EnvironmentTest, \n",
    "                                            repetitions=repetitions, \n",
    "                                            sign_level=sign_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load:\n",
    "    # Run experiment with TwoSampleConfounderTest\n",
    "    conf_test_res  =fast_experiment(dist_param_list,\n",
    "                                            nbr_env,\n",
    "                                            nbr_samples,\n",
    "                                            conf_strength,\n",
    "                                            SimulateClass, \n",
    "                                            FullTwoSampleConfounderTest, \n",
    "                                            repetitions=repetitions, \n",
    "                                            sign_level=sign_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test_res.sort_values('Y_b', inplace=True)\n",
    "conf_test_res.sort_values('Y_b', inplace=True)\n",
    "\n",
    "# Filter with or without confounding\n",
    "env_test_res_cs1 = env_test_res[env_test_res.confounder_strength == 1]\n",
    "env_test_res_cs0 = env_test_res[env_test_res.confounder_strength == 0]\n",
    "\n",
    "conf_test_res_cs1 = conf_test_res[conf_test_res.confounder_strength == 1]\n",
    "conf_test_res_cs0 = conf_test_res[conf_test_res.confounder_strength == 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std = lambda p : np.sqrt(p*(1-p)/repetitions)\n",
    "std_env = std(env_test_res_cs0.reject_rate.values) \n",
    "std_conf_test = std(conf_test_res_cs0.reject_rate.values) \n",
    "\n",
    "\n",
    "plt.plot(env_test_res_cs0.Y_b, env_test_res_cs0.reject_rate, label='$Y \\perp E \\mid T$', marker=marker_dict['EnvironmentTest']) \n",
    "plt.fill_between(env_test_res_cs0.Y_b, env_test_res_cs0.reject_rate-std_env, env_test_res_cs0.reject_rate+std_env, alpha=0.5)\n",
    "\n",
    "plt.plot(conf_test_res_cs0.Y_b, conf_test_res_cs0.reject_rate, label='$T_j \\perp Y_i \\mid T_i$ (ours)', marker=marker_dict['FullTwoSampleConfounderTest'])\n",
    "plt.fill_between(conf_test_res_cs0.Y_b, conf_test_res_cs0.reject_rate-std_conf_test, conf_test_res_cs0.reject_rate+std_conf_test, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.ylabel('Probability of false detection')\n",
    "plt.xlabel('Standard deviation $\\sigma_{\\\\theta_Y}$')\n",
    "plt.ylim([-.05,1.05])\n",
    "#plt.legend()\n",
    "\n",
    "path = f'results/figures/comparison_cs0_{timestamp}.pdf'\n",
    "plt.savefig(path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_env = std(env_test_res_cs1.reject_rate.values) \n",
    "std_conf_test = std(conf_test_res_cs1.reject_rate.values) \n",
    "\n",
    "\n",
    "plt.plot(env_test_res_cs1.Y_b, env_test_res_cs1.reject_rate, label='$Y \\perp E \\mid T$', marker=marker_dict['EnvironmentTest']) \n",
    "plt.fill_between(env_test_res_cs1.Y_b, env_test_res_cs1.reject_rate-std_env, env_test_res_cs1.reject_rate+std_env, alpha=0.5)\n",
    "\n",
    "plt.plot(conf_test_res_cs1.Y_b, conf_test_res_cs1.reject_rate, label='$T_j \\perp Y_i \\mid T_i$ (ours)', marker=marker_dict['FullTwoSampleConfounderTest'])\n",
    "plt.fill_between(conf_test_res_cs1.Y_b, conf_test_res_cs1.reject_rate-std_conf_test, conf_test_res_cs1.reject_rate+std_conf_test, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.ylabel('Probability of correct detection')\n",
    "plt.xlabel('Standard deviation $\\sigma_{\\\\theta_Y}$')\n",
    "plt.ylim([-.05,1.05])\n",
    "plt.legend()\n",
    "\n",
    "path = f'results/figures/comparison_cs1_{timestamp}.pdf'\n",
    "plt.savefig(path, format='pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37fca3988ddb6aaabeb4844171b7eb820257357272ea2dfe95297d34f3bc7351"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('CI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
